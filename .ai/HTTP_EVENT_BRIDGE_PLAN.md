# HTTP Event Bridge Plan

## Overview

Transition the lattice CLI's communication with opencode from polling-based file
watching to an HTTP-based event bridge. This creates infrastructure for
real-time event streaming and positions the system for future app-based
interfaces.

---

## Current Architecture

```
┌─────────────┐         tmux spawn          ┌─────────────┐
│   Lattice   │ ────────────────────────►   │  OpenCode   │
│   (Go TUI)  │                             │  (Claude)   │
│             │                             │             │
│   polls     │   ◄── file artifacts ──     │   writes    │
│   for files │                             │   files     │
└─────────────┘                             └─────────────┘
```

**Limitations:**

- No real-time feedback during execution
- Can't know when opencode starts/finishes tasks
- Polling wastes resources
- Hard to debug what's happening in the agent

---

## Proposed Architecture

```
┌─────────────┐                             ┌─────────────┐
│   Lattice   │         tmux spawn          │  OpenCode   │
│   (Go TUI)  │ ────────────────────────►   │  (Claude)   │
│             │                             │             │
│  HTTP       │   ◄── HTTP POST events ──   │  TS Plugin  │
│  Server     │                             │  (bridge)   │
│  :8765      │                             │             │
└─────────────┘                             └─────────────┘
```

**Benefits:**

- Real-time event streaming
- Know exactly when tasks start/complete
- Capture model responses, tool calls, errors
- Same HTTP endpoint works for future web/Electron apps
- Plugin is decoupled - can be disabled without breaking core flow

---

## Components

### 1. Go HTTP Server (internal/eventbridge/server.go)

A lightweight HTTP server that:

- Starts when lattice starts (or on-demand)
- Listens on a configurable port (default: 8765)
- Accepts POST requests with event payloads
- Routes events to the appropriate workflow/module

**Endpoints:**

| Method | Path                        | Description                         |
| ------ | --------------------------- | ----------------------------------- |
| POST   | `/events`                   | Receive events from opencode plugin |
| GET    | `/health`                   | Health check for plugin startup     |
| POST   | `/events/:workflow/:module` | Scoped events for specific modules  |

**Health Endpoint Response:**

```json
{
  "status": "ready", // "ready" | "starting" | "draining"
  "version": "1.0.0", // Bridge protocol version
  "router_ready": true, // Event router initialized
  "uptime_seconds": 42
}
```

The plugin should wait for `status: "ready"` before sending events.

**Event Schema:**

```go
type Event struct {
    Version    int             `json:"version"`     // Schema version (currently 1)
    EventID    string          `json:"event_id"`    // Unique ID for deduplication (UUID)
    Sequence   int64           `json:"sequence"`    // Monotonic sequence number per session
    Type       string          `json:"type"`        // "model_response", "tool_call", "error", etc.
    ClientTime time.Time       `json:"client_time"` // Timestamp from plugin (may have clock skew)
    ServerTime time.Time       `json:"server_time"` // Set by server on receipt (authoritative)
    SessionID  string          `json:"session_id"`  // Generated by lattice, passed to opencode via env
    ModuleID   string          `json:"module_id"`   // Which lattice module this relates to
    Workflow   string          `json:"workflow"`    // Active workflow ID
    Payload    json.RawMessage `json:"payload"`     // Event-specific data (max 1MB, truncated if larger)
}
```

**Delivery Semantics:** At-least-once delivery. The plugin retries on failure;
the server uses `event_id` for deduplication and `sequence` for ordering within
a session.

### 2. OpenCode TypeScript Plugin (plugins/lattice-bridge/index.ts)

A TypeScript plugin that:

- Hooks into opencode's event system
- Formats events and POSTs them to the Go server
- Gracefully handles server unavailability
- Includes session/module context in events

**Key Events to Capture:**

| OpenCode Event   | Lattice Event Type | Purpose                                            |
| ---------------- | ------------------ | -------------------------------------------------- |
| `model.response` | `model_response`   | Know when Claude responds                          |
| `tool.call`      | `tool_call`        | Track tool usage                                   |
| `tool.result`    | `tool_result`      | Know when tools complete                           |
| `session.start`  | `session_start`    | Session began                                      |
| `session.end`    | `session_end`      | Session finished (includes success/failure status) |
| `error`          | `error`            | Capture failures                                   |

### 3. Integration with Workflow Engine

The event bridge integrates with the existing module system:

```
skillModule.Run()
    ├── Start HTTP server (if not running)
    ├── Subscribe to events for this module (BEFORE spawn)
    ├── Spawn opencode with LATTICE_BRIDGE_URL env var
    └── Return immediately (StatusNeedsInput)

Event arrives via HTTP
    ├── Route to correct workflow/module (buffer if no subscriber yet)
    ├── Update module state
    └── If session_end → trigger completion check
```

**Critical:** Subscribe to events BEFORE spawning opencode. This prevents a race
where events arrive before the module is listening. As a fallback, the router
buffers events per-session until a subscriber attaches.

---

## Implementation Phases

### Phase 1: HTTP Server Foundation

**Goal:** Standalone HTTP server that receives and logs events.

**Tasks:**

1. Create `internal/eventbridge/` package
2. Implement basic HTTP server with `/events` endpoint
3. Define event types and payload structures
4. Add server lifecycle management (start/stop)
5. Integrate server startup with lattice app init
6. Add configuration for port, enabled/disabled

**Files:**

- `internal/eventbridge/server.go` - HTTP server
- `internal/eventbridge/events.go` - Event types
- `internal/eventbridge/handler.go` - Request handlers
- `internal/eventbridge/config.go` - Configuration

**Testing:**

- Unit tests with httptest
- Can POST events via curl to verify

### Phase 2: OpenCode TypeScript Plugin

**Goal:** TS plugin that captures events and POSTs to lattice.

**Tasks:**

1. Create plugin directory structure
2. Implement event subscriptions per opencode plugin API
3. Add HTTP client with retry logic
4. Handle graceful degradation (server down)
5. Pass module/workflow context via env vars
6. Package for easy installation

**Files:**

- `plugins/lattice-bridge/index.ts` - Main plugin
- `plugins/lattice-bridge/events.ts` - Event formatters
- `plugins/lattice-bridge/client.ts` - HTTP client
- `plugins/lattice-bridge/package.json` - Dependencies

**Plugin Configuration (in opencode):**

```jsonc
{
  "plugins": {
    "lattice-bridge": {
      "enabled": true,
      "serverUrl": "http://localhost:8765",
    },
  },
}
```

### Phase 3: Event Routing & Subscription

**Goal:** Route events to the correct module and enable subscriptions.

**Tasks:**

1. Add event router that maps session → module
2. Implement pub/sub for modules to subscribe to events
3. Create channel-based event delivery to TUI
4. Handle events for multiple concurrent modules
5. Add event filtering (only forward relevant events)

**Architecture:**

```go
type EventRouter struct {
    subscriptions map[string][]chan Event  // moduleID → subscribers
    sessions      map[string]string        // sessionID → moduleID
}

func (r *EventRouter) Subscribe(moduleID string) <-chan Event
func (r *EventRouter) Route(event Event)
```

### Phase 4: Module Integration

**Goal:** Update skillModule to use events instead of polling.

**Tasks:**

1. Modify `skillModule.Run()` to register with event bridge
2. Pass bridge URL and module context to opencode via env
3. Update `IsComplete()` to use session_end events
4. Add real-time progress updates to TUI
5. Keep file-based completion check as fallback

**Environment Variables for OpenCode (v1 Contract):**

| Variable                 | Required | Description                                              |
| ------------------------ | -------- | -------------------------------------------------------- |
| `LATTICE_BRIDGE_URL`     | Yes      | Full URL to event bridge (e.g., `http://127.0.0.1:8765`) |
| `LATTICE_MODULE_ID`      | Yes      | Module identifier (e.g., `anchor-docs`)                  |
| `LATTICE_WORKFLOW_ID`    | Yes      | Workflow identifier (e.g., `commission-work`)            |
| `LATTICE_SESSION_ID`     | Yes      | UUID generated by lattice for this session               |
| `LATTICE_BRIDGE_TOKEN`   | No       | Auth token (required if server uses token auth)          |
| `LATTICE_BRIDGE_VERSION` | No       | Contract version, defaults to `1`                        |

**Contract Versioning:** If the env var contract changes, bump
`LATTICE_BRIDGE_VERSION`. The plugin should check this and warn if it doesn't
recognize the version.

**Note:** The session ID is generated by lattice (the orchestrator) and passed
to opencode. This ensures lattice can correlate incoming events with the correct
module instance.

### Phase 5: TUI Enhancement

**Goal:** Show real-time events in the workflow view.

**Tasks:**

1. Add event display area to workflow view
2. Show model responses as they arrive
3. Display tool call summaries
4. Indicate active/idle state per module
5. Add event log scrollback

**UI Mockup:**

```
Workflow: commission-work · Status: Running
Ready modules: 3

❯ anchor-docs                  Running
  [14:32:01] Tool: Read - reading ARCHITECTURE.md
  [14:32:03] Model response: "I'll analyze the current..."

  action-plan                   Blocked
  Blocked by: anchor-docs
```

### Phase 6: Advanced Features (Future)

**Goal:** Leverage the HTTP infrastructure for more capabilities.

**Potential Features:**

- WebSocket upgrade for true bidirectional streaming
- Remote TUI (run lattice headless, view via web)
- Event persistence/replay for debugging
- Module-to-module messaging
- Progress percentage estimation from events

---

## Technical Decisions

### HTTP Client for TS Plugin

The TS plugin is a client, not a server - it just POSTs events to the Go server.
Use built-in `fetch` (Node 18+) or bundle a minimal HTTP client like `undici`.
No framework needed.

### Why Not WebSocket from the Start?

- HTTP POST is simpler to implement and debug
- Events are naturally request/response shaped
- Can upgrade to WebSocket later if needed
- Easier to handle reconnection

### Port Selection & Discovery

Default: `8765` (arbitrary, unlikely to conflict)

**Configuration Options:**

- Environment variable: `LATTICE_BRIDGE_PORT`
- Config file: `.lattice/config.yaml`
- Auto-select available port if default is busy

**Port Discovery:** The primary discovery mechanism is via environment variable.
When lattice spawns opencode, it passes the actual bound port in
`LATTICE_BRIDGE_URL`. The plugin reads this directly - no file discovery needed.

**Port File (optional, for debugging):** Write to `.lattice/bridge-<pid>.port`
(using lattice's PID) to avoid collision between instances. On startup:

1. Clean up stale port files (check if PID is still running)
2. Write new port file after successful bind
3. Delete port file on graceful shutdown

### Security

**Network Binding:**

- Bind to `127.0.0.1` (loopback) only by default
- Never bind to `0.0.0.0` without explicit configuration
- This prevents event injection from other machines on the network

**Token Authentication (optional):**

- Generate a short-lived token on server start
- Pass token to opencode via `LATTICE_BRIDGE_TOKEN` env var
- Plugin includes token in `Authorization: Bearer <token>` header
- Required if binding to non-loopback interfaces

### Request Limits

**Payload Size:**

- Max request body: 1MB
- Reject larger requests with 413 Payload Too Large
- Plugin should truncate large payloads (e.g., model responses) before sending

**PII/Sensitive Data:**

- Model responses and tool results may contain sensitive data
- Consider redaction rules for known patterns (API keys, passwords)
- Log events at debug level only, not info

### Backpressure Handling

**Bounded Queues:**

- Each subscriber channel has a bounded buffer (default: 100 events)
- If buffer is full, drop oldest events (not newest)
- Emit metric/log when drops occur

**HTTP Handler:**

- Handler writes to channel with non-blocking send
- Returns 202 Accepted immediately (don't wait for processing)
- Returns 503 Service Unavailable if router is overloaded

**Drop Policy:**

- Prefer dropping `model_response` (high volume) over `session_end` (critical)
- Never drop `session_end` or `error` events if possible

### Error Handling

**Plugin can't reach server:**

- Log warning, continue without events
- Don't break opencode functionality
- Retry with exponential backoff (max 3 retries per event)

**Server receives malformed event:**

- Log and discard
- Return 400 Bad Request
- Don't crash

**Unknown event types:**

- Accept and route (forward compatibility)
- Log at debug level

### Graceful Shutdown

When lattice shuts down:

1. Stop accepting new HTTP connections
2. Allow brief drain period (e.g., 500ms) for in-flight requests
3. Close event channels to notify subscribers
4. Clean up `.lattice/bridge-<pid>.port` file

### Completion Detection Precedence

Both event-based and file-based completion detection may coexist during
migration:

1. **Events win if received** - A `session_end` event immediately marks the
   module complete
2. **File-based is fallback** - Only checked if no events received within
   timeout period
3. **No double-completion** - Once complete via either method, ignore the other

This prevents race conditions while maintaining backward compatibility.

**Session End Payload:**

```go
type SessionEndPayload struct {
    Success bool   `json:"success"`          // true if session completed normally
    Reason  string `json:"reason"`           // "completed", "error", "cancelled", "timeout"
    Error   string `json:"error,omitempty"`  // Error message if success=false
}
```

The module maps `session_end` to its own state:

- `success=true, reason=completed` → Module status = Completed
- `success=false, reason=error` → Module status = Failed
- `success=false, reason=cancelled` → Module status = Cancelled

---

## File Structure After Implementation

```
lattice/
├── internal/
│   ├── eventbridge/
│   │   ├── server.go          # HTTP server
│   │   ├── server_test.go
│   │   ├── events.go          # Event types
│   │   ├── handler.go         # Request handlers
│   │   ├── handler_test.go
│   │   ├── router.go          # Event routing
│   │   ├── router_test.go
│   │   └── config.go          # Configuration
│   └── ...
├── plugins/
│   └── lattice-bridge/
│       ├── index.ts           # Main plugin entry
│       ├── events.ts          # Event formatting
│       ├── client.ts          # HTTP client
│       ├── package.json
│       └── tsconfig.json
└── ...
```

---

## Required Test Coverage

### Server Tests (`server_test.go`)

- Request body exceeds 1MB limit → 413 response
- Malformed JSON → 400 response
- Valid JSON but missing required fields → 400 response
- Unknown event type → 202 (accepted, forward compatible)
- Invalid session/module/workflow IDs → 400 response
- Health endpoint returns correct status during lifecycle
- Graceful shutdown completes in-flight requests

### Router Tests (`router_test.go`)

- Concurrent subscribe/unsubscribe safety
- Events buffer until subscriber attaches
- Duplicate event_id deduplicated
- Events delivered in sequence order
- Channel overflow triggers drop (oldest first)
- Critical events (`session_end`) prioritized during overflow
- Unsubscribe cleans up resources

### Handler Tests (`handler_test.go`)

- Token auth rejects invalid/missing token
- Token auth accepts valid token
- Non-blocking write to subscriber channels
- 503 returned when router overloaded

### Integration Tests

- Plugin retry behavior when server restarts mid-session
- Event-based completion fires before file-based fallback
- File-based fallback works when no events received
- Multiple concurrent modules receive correct events
- Stale port file cleaned up on startup

### Plugin Tests (TypeScript)

- Graceful degradation when server unreachable
- Exponential backoff respects max retries
- Large payloads truncated before send
- All required env vars validated on startup
- Sequence numbers increment correctly

---

## Migration Path

The HTTP event bridge can be introduced **incrementally** without breaking
existing functionality:

1. **Phase 1-2**: Server and plugin exist but are optional. File-based
   completion still works.

2. **Phase 3-4**: Events supplement polling. Both mechanisms coexist.

3. **Phase 5+**: Events become primary. Polling becomes fallback for edge cases.

This means you can ship early phases and get value immediately while building
toward the full vision.

---

## Open Questions

1. **Event persistence**: Should events be logged to disk for debugging/replay?
   - Decision: Start without. In-memory loss is acceptable for v1. Add
     persistence in Phase 6 if needed for debugging.

2. **Multi-instance**: What if multiple lattice instances run simultaneously?
   - Decision: Each instance auto-selects an available port and passes it via
     env var. Port files use PID suffix to avoid collision.

3. **Security**: Should the HTTP endpoint require authentication?
   - Decision: Loopback-only binding by default (no auth needed). Token auth
     required if binding to non-loopback.

4. **Compression**: Should events be compressed?
   - Decision: No - events are small, latency matters more than bandwidth.

5. **OpenCode session IDs**: Should we include opencode's internal session ID
   for debugging?
   - Recommendation: Yes, include as optional `opencode_session_id` field in
     payload for correlation.

---

## Success Criteria

**Phase 1-2 Complete When:**

- [ ] Go server starts with lattice
- [ ] TS plugin posts events successfully
- [ ] Events appear in lattice logs

**Phase 3-4 Complete When:**

- [ ] Events route to correct modules
- [ ] Module completion detected via session_end event
- [ ] Fallback to file polling still works

**Phase 5 Complete When:**

- [ ] TUI shows real-time event stream
- [ ] Users can see model responses as they happen
- [ ] System feels responsive and observable

---

## Appendix: OpenCode Plugin Events Reference

Based on [OpenCode Plugin Docs](https://opencode.ai/docs/plugins/#events), key
events include:

```typescript
// Session lifecycle
opencode.on('session.start', (session) => {...})
opencode.on('session.end', (session, reason) => {...})

// Model interactions
opencode.on('model.request', (request) => {...})
opencode.on('model.response', (response) => {...})
opencode.on('model.error', (error) => {...})

// Tool usage
opencode.on('tool.call', (tool, args) => {...})
opencode.on('tool.result', (tool, result) => {...})

// File operations
opencode.on('file.read', (path) => {...})
opencode.on('file.write', (path, content) => {...})
```

The plugin should subscribe to these and transform them into the lattice event
schema.

---

## Advanced Backlog

The foundation (Phase 1-4) is live, so we can look ahead at larger bridge
capabilities. The following backlog orders the work by impact/effort with
explicit spike outcomes and the decision on what to build next.

| Priority | Capability                     | Summary                                                                                                                                                                | Spike Notes / Open Questions                                                                                                                                                                  | Next Action                                                                                                                                           |
| -------- | ------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| P1       | **WebSocket upgrade**          | Replace the current HTTP POST pipeline with an optional WebSocket transport so events stream with near-zero latency and the bridge can push commands back to OpenCode. | ✅ Feasibility spike confirmed Go net/http + Gorilla WebSocket fits without pulling extra deps. Need auth handshake (reuse bridge token) and a feature flag so older plugins stay functional. | Build a prototype WS endpoint that mirrors `/events`, gated by `LATTICE_BRIDGE_MODE=websocket`. Update plugin with auto-negotiation + retry fallback. |
| P2       | **Remote TUI**                 | Expose bridge data over WebSocket so future Electron/web surfaces can mirror the workflow view.                                                                        | Needs a thin read-only API for session summaries (not a full RPC surface). Depends on WebSocket upgrade. Must solve auth (probably reuse CLI token + CSRF guard).                             | After WS prototype, formalize a JSON schema for “workflow snapshot” and expose it at `/stream/workflow`.                                              |
| P3       | **Event persistence + replay** | Store bridge events so operators can audit prior runs and rebuild telemetry after restarts.                                                                            | SQLite fits (already linked) but needs retention policy and per-session pruning. Must redact payloads before storage.                                                                         | Define retention knobs, add `event_store` package, and teach router to dual-write to the store.                                                       |
| P4       | **Module-to-module messaging** | Allow modules to send structured signals to siblings (e.g., anchor-docs instructing work-process).                                                                     | Needs routing rules + ACLs so a compromised module cannot poke others. Likely another topic layered atop router subscriptions.                                                                | Spike a minimal contract (`type`, `payload`, `targets`) and add filtering hooks to router.                                                            |
| P5       | **Progress estimation**        | Compute per-module progress based on event cadence (tool activity, model responses) to show “% complete” in the UI.                                                    | Requires heuristics + optionally ML/regression. Needs persisted historical runtimes per module.                                                                                               | After event persistence lands, collect metrics and prototype heuristics (e.g., ratio of tool.result/model.response).                                  |

### Decision: build the WebSocket upgrade next

The backlog now has a clear dependency chain: remote TUI and persistence both
benefit from the WebSocket transport, so that is the highest leverage next
feature. The spike confirmed the approach and highlighted the need for a feature
flag plus auth reuse. Once the WS endpoint is in place we can immediately start
streaming the workflow snapshot to remote clients and reuse the same transport
for future messaging work.
